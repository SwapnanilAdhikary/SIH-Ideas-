{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa3baaef-19c9-4de9-b3b2-01427ee8d619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded.\n",
      "Training model...\n",
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▍                                                                      | 1/149 [01:20<3:19:35, 80.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/149, Loss: 0.15214115381240845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|█████▏                                                                | 11/149 [13:14<2:38:48, 69.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10/149, Loss: 0.010839411988854408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  14%|█████████▊                                                            | 21/149 [24:00<2:17:33, 64.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20/149, Loss: 0.006725357845425606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  21%|██████████████▌                                                       | 31/149 [34:57<2:10:22, 66.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 30/149, Loss: 0.004736681468784809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  28%|███████████████████▎                                                  | 41/149 [46:00<1:59:39, 66.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 40/149, Loss: 0.003098583547398448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  34%|███████████████████████▉                                              | 51/149 [57:01<1:47:20, 65.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50/149, Loss: 0.00221150740981102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  41%|███████████████████████████▊                                        | 61/149 [1:07:19<1:37:35, 66.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 60/149, Loss: 0.0019531032303348184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  48%|████████████████████████████████▍                                   | 71/149 [1:18:52<1:30:58, 69.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 70/149, Loss: 0.0014893243787810206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  54%|████████████████████████████████████▉                               | 81/149 [1:30:19<1:17:58, 68.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 80/149, Loss: 0.0012645451352000237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  61%|█████████████████████████████████████████▌                          | 91/149 [1:41:48<1:07:41, 70.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 90/149, Loss: 0.0012808674946427345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  68%|██████████████████████████████████████████████▊                      | 101/149 [1:53:11<54:46, 68.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100/149, Loss: 0.0010609830496832728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  74%|███████████████████████████████████████████████████▍                 | 111/149 [2:04:54<45:42, 72.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 110/149, Loss: 0.0009559508762322366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  81%|████████████████████████████████████████████████████████             | 121/149 [2:17:18<32:57, 70.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 120/149, Loss: 0.0007668482139706612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  88%|████████████████████████████████████████████████████████████▋        | 131/149 [2:28:32<19:55, 66.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 130/149, Loss: 0.0007557718781754375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  95%|█████████████████████████████████████████████████████████████████▎   | 141/149 [2:39:28<08:47, 65.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 140/149, Loss: 0.000819932552985847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████| 149/149 [2:47:35<00:00, 67.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1, Average Loss: 0.004789141528683421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from tqdm import tqdm  \n",
    "\n",
    "class FrameInterpolationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(6, 64, 3, 1, 1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(64, 128, 3, 1, 1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ) for _ in range(3)\n",
    "        ])\n",
    "        self.resize = nn.Upsample(size=(90, 160), mode='bilinear', align_corners=False)\n",
    "        self.fusion_conv = nn.Conv2d(384, 128, 3, 1, 1)\n",
    "        self.upsample_conv = nn.ConvTranspose2d(128, 3, 3, 2, 1, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature_maps = [extractor(x) for extractor in self.feature_extractor]\n",
    "        feature_maps_resized = [self.resize(fm) for fm in feature_maps]\n",
    "        x = torch.cat(feature_maps_resized, 1)\n",
    "        x = F.relu(self.fusion_conv(x))\n",
    "        x = self.upsample_conv(x)\n",
    "        return x\n",
    "\n",
    "class FrameInterpolationDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.num_frames_per_video = 190\n",
    "        self.start_frame_number = 100000  \n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.num_frames_per_video * 25  \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_idx = idx % self.num_frames_per_video\n",
    "        video_idx = idx // self.num_frames_per_video\n",
    "        frame_number = self.start_frame_number + frame_idx\n",
    "\n",
    "        # Create paths for the frames\n",
    "        frame_folder = self.root_dir\n",
    "        frame1_path = os.path.join(frame_folder, f\"RLCAFTCONF-C0_{frame_number:06d}.jpeg\")\n",
    "        frame2_path = os.path.join(frame_folder, f\"RLCAFTCONF-C0_{frame_number + 1:06d}.jpeg\")\n",
    "        target_path = os.path.join(frame_folder, f\"RLCAFTCONF-C0_{frame_number + 2:06d}.jpeg\")\n",
    "\n",
    "        \n",
    "        frame1, frame2, target = map(Image.open, (frame1_path, frame2_path, target_path))\n",
    "\n",
    "        \n",
    "        if self.transform:\n",
    "            frame1, frame2, target = map(self.transform, (frame1, frame2, target))\n",
    "\n",
    "        return frame1, frame2, target\n",
    "\n",
    "model = FrameInterpolationModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "dataset = FrameInterpolationDataset(root_dir='C:\\\\Users\\\\adhik\\\\Frame Interpolation\\\\EPFL-RLC_dataset\\\\frames\\\\cam0', transform=transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True) \n",
    "print(\"Dataset loaded.\")\n",
    "\n",
    "\n",
    "print(\"Training model...\")\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch_idx, (frame1, frame2, target) in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch+1}\")):\n",
    "        inputs = torch.cat((frame1, frame2), 1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        target_resized = F.interpolate(target, size=outputs.shape[2:], mode='bilinear', align_corners=False)\n",
    "        loss = criterion(outputs, target_resized)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "    print(f'\\nEpoch {epoch+1}/{num_epochs}, Average Loss: {avg_epoch_loss}', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fbd34ce-7004-4fe0-9b8a-4500f884f27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'frame_interpolation_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dee90c-8d54-4563-998f-c72fe892718d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
